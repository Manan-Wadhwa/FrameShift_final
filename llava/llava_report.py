"""
LLaVA Report Generator
Generates natural language explanations of detected differences
"""
import numpy as np
import cv2
from PIL import Image
import base64
from io import BytesIO


# Global LLaVA model (lazy loaded)
_llava_model = None
_llava_tokenizer = None


def get_llava_model():
    """Lazy load LLaVA model"""
    global _llava_model, _llava_tokenizer
    if _llava_model is None:
        try:
            from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration
            import torch

            model_id = "llava-hf/llava-v1.6-mistral-7b-hf"
            _llava_model = LlavaNextForConditionalGeneration.from_pretrained(
                model_id,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                low_cpu_mem_usage=True
            )
            _llava_tokenizer = LlavaNextProcessor.from_pretrained(model_id)

            device = "cuda" if torch.cuda.is_available() else "cpu"
            _llava_model.to(device)
            _llava_model.eval()

        except Exception as e:
            print(f"Warning: LLaVA loading failed: {e}")
            _llava_model = None
            _llava_tokenizer = None

    return _llava_model, _llava_tokenizer


def create_composite_image(ref_img, test_img, heatmap, mask):
    """
    Create a composite image showing reference, test, heatmap, and mask
    """
    # Resize all to same size
    h, w = ref_img.shape[:2]

    # Create 2x2 grid
    top_row = np.hstack([ref_img, test_img])
    bottom_row = np.hstack([heatmap, cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)])

    composite = np.vstack([top_row, bottom_row])

    return composite


def generate_rule_based_report(pipeline_type, severity=None, features=None, mask_area=None, pipeline_name=None):
    """
    Comprehensive fallback rule-based report generation
    Provides detailed analysis when LLaVA is unavailable
    """
    import time

    # Extract feature details if available
    texture_var = features.get('texture_var', 0) if features else 0
    edge_density = features.get('edge_density', 0) if features else 0
    color_shift = features.get('color_shift', 0) if features else 0
    entropy_val = features.get('entropy', 0) if features else 0

    # Calculate change percentage if mask area available
    change_pct = (mask_area / (512 * 512) * 100) if mask_area else 0

    # Generate timestamp
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")

    if pipeline_type == "semantic":
        # Determine specific semantic change type
        if color_shift > 0.3:
            change_type = "Major Color Scheme Modification"
            details = "Significant color palette changes detected across the vehicle surface."
        elif color_shift > 0.15:
            change_type = "Moderate Livery Update"
            details = "Notable changes in livery design, sponsor logos, or branding elements."
        else:
            change_type = "Subtle Design Variation"
            details = "Minor design element modifications or subtle color adjustments."

        report = f"""**ðŸŽ¨ SEMANTIC CHANGE ANALYSIS REPORT**
Generated by: {pipeline_name or 'Manual Analysis System'}
Timestamp: {timestamp}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**DETECTION SUMMARY**
Change Type: {change_type}
Affected Area: {change_pct:.1f}% of vehicle surface

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**DETAILED FINDINGS**

{details}

Visual Characteristics:
â€¢ Color Shift Index: {color_shift:.3f} {'(High - Major changes)' if color_shift > 0.3 else '(Medium - Noticeable changes)' if color_shift > 0.15 else '(Low - Subtle changes)'}
â€¢ Texture Complexity: {texture_var:.1f} {'(Smooth surfaces)' if texture_var < 300 else '(Textured surfaces)'}
â€¢ Edge Density: {edge_density:.3f} {'(Clean geometric changes)' if edge_density < 0.2 else '(Complex boundary changes)'}
â€¢ Region Entropy: {entropy_val:.3f}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**KEY OBSERVATIONS**

1. Color & Livery Changes:
   {'âœ“' if color_shift > 0.15 else 'â—‹'} Primary color scheme modifications detected
   {'âœ“' if color_shift > 0.2 else 'â—‹'} Sponsor branding or logo changes identified
   {'âœ“' if edge_density > 0.15 else 'â—‹'} Design element boundary alterations

2. Surface Characteristics:
   {'âœ“' if texture_var < 400 else 'â—‹'} Smooth, painted surface changes
   {'âœ“' if entropy_val > 4.0 else 'â—‹'} High visual complexity in modified regions
   {'âœ“' if change_pct > 5 else 'â—‹'} Significant coverage area affected

3. Change Pattern Analysis:
   â€¢ Pattern: {'Localized changes' if change_pct < 10 else 'Widespread modifications' if change_pct < 30 else 'Major vehicle-wide updates'}
   â€¢ Distribution: {'Concentrated in specific region' if change_pct < 15 else 'Distributed across multiple areas'}
   â€¢ Consistency: {'Uniform appearance' if texture_var < 300 else 'Varied texture patterns'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ASSESSMENT & RECOMMENDATIONS**

Classification: SEMANTIC MODIFICATION (Intentional Design Change)
Confidence Level: {'High' if color_shift > 0.25 else 'Medium' if color_shift > 0.12 else 'Low'}

Recommendations:
âœ“ Verify changes comply with FIA technical regulations
âœ“ Confirm livery updates match team specifications
âœ“ Check sponsor branding placement and sizing
âœ“ Document changes for official race records
âœ“ No immediate safety concerns - cosmetic modifications only

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**TECHNICAL NOTES**
This is an automated rule-based analysis generated without vision-language model inference.
For enhanced natural language descriptions, install LLaVA model components.
"""

    else:  # anomaly
        severity_level = "HIGH" if severity and severity > 0.7 else "MEDIUM" if severity and severity > 0.4 else "LOW"
        severity_emoji = "ðŸ”´" if severity and severity > 0.7 else "ðŸŸ¡" if severity and severity > 0.4 else "ðŸŸ¢"
        severity_val = severity if severity else 0.0

        # Determine anomaly type
        if texture_var > 800 and edge_density > 0.4:
            anomaly_type = "Severe Structural Damage"
            concern_level = "CRITICAL"
        elif texture_var > 500 or edge_density > 0.3:
            anomaly_type = "Surface Irregularities"
            concern_level = "HIGH"
        else:
            anomaly_type = "Minor Texture Anomaly"
            concern_level = "MODERATE"

        report = f"""**âš ï¸ ANOMALY DETECTION REPORT**
Generated by: {pipeline_name or 'Manual Analysis System'}
Timestamp: {timestamp}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**DETECTION SUMMARY**
Severity Level: {severity_emoji} {severity_level}
Anomaly Score: {severity_val:.3f}/1.000
Concern Level: {concern_level}
Affected Area: {change_pct:.1f}% of vehicle surface

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ANOMALY CLASSIFICATION**

Type: {anomaly_type}

{'ðŸ”´ CRITICAL FINDINGS - Immediate attention required!' if concern_level == 'CRITICAL' else 'ðŸŸ¡ WARNING - Investigation recommended' if concern_level == 'HIGH' else 'ðŸŸ¢ NOTICE - Monitor for changes'}

Anomaly Characteristics:
â€¢ Texture Variance: {texture_var:.1f} {'(Extremely irregular)' if texture_var > 800 else '(Highly irregular)' if texture_var > 500 else '(Moderately irregular)' if texture_var > 300 else '(Slightly irregular)'}
â€¢ Edge Density: {edge_density:.3f} {'(Dense crack patterns)' if edge_density > 0.4 else '(Moderate surface breaks)' if edge_density > 0.3 else '(Light texture changes)'}
â€¢ Surface Entropy: {entropy_val:.3f}
â€¢ Pattern Complexity: {'High - Multiple defect types' if entropy_val > 5.5 else 'Medium - Localized issues' if entropy_val > 4.5 else 'Low - Uniform anomaly'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**DETAILED ANALYSIS**

1. Surface Condition Assessment:
   {'âš ï¸' if texture_var > 600 else 'âœ“'} Texture pattern analysis: {'ABNORMAL' if texture_var > 600 else 'ACCEPTABLE'}
   {'âš ï¸' if edge_density > 0.35 else 'âœ“'} Edge discontinuity check: {'FAILED' if edge_density > 0.35 else 'PASSED'}
   {'âš ï¸' if severity_val > 0.6 else 'âœ“'} Structural integrity: {'COMPROMISED' if severity_val > 0.6 else 'INTACT'}

2. Potential Defect Types Identified:
   {'âœ“' if edge_density > 0.3 else 'â—‹'} Crack formations or fractures
   {'âœ“' if texture_var > 500 else 'â—‹'} Surface deformations or dents
   {'âœ“' if texture_var > 700 and edge_density > 0.25 else 'â—‹'} Material degradation or wear
   {'âœ“' if entropy_val > 5.0 else 'â—‹'} Irregular texture patterns
   {'âœ“' if severity_val > 0.5 else 'â—‹'} Significant deviation from normal

3. Spatial Distribution:
   â€¢ Coverage: {change_pct:.1f}% of inspected area
   â€¢ Pattern: {'Scattered multiple points' if entropy_val > 5.0 else 'Concentrated single region'}
   â€¢ Severity gradient: {'Progressive deterioration' if severity_val > 0.6 else 'Isolated anomaly'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**RISK ASSESSMENT**

Safety Impact: {'ðŸ”´ HIGH - Potential safety hazard' if severity_val > 0.7 else 'ðŸŸ¡ MEDIUM - Requires evaluation' if severity_val > 0.4 else 'ðŸŸ¢ LOW - Monitor situation'}
Performance Impact: {'Significant degradation likely' if severity_val > 0.6 else 'Possible performance reduction' if severity_val > 0.3 else 'Minimal impact expected'}
Urgency: {'IMMEDIATE ACTION REQUIRED' if severity_val > 0.7 else 'Inspection within 24 hours' if severity_val > 0.4 else 'Schedule routine check'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**RECOMMENDATIONS**

Immediate Actions:
{'1. âš ï¸ CEASE OPERATIONS - Do not use vehicle until inspected' if severity_val > 0.7 else '1. Schedule detailed visual inspection by qualified technician'}
2. Document anomaly location and extent with high-resolution imagery
3. {'Conduct structural integrity testing' if severity_val > 0.5 else 'Perform surface condition assessment'}
4. {'Replace or repair affected component immediately' if severity_val > 0.6 else 'Monitor for progression over time'}
5. Review recent usage history for potential causative factors

Follow-up:
â€¢ {'Emergency repair required before next use' if severity_val > 0.7 else 'Plan maintenance at next scheduled service' if severity_val > 0.4 else 'Continue monitoring'}
â€¢ {'Consult with safety team and structural engineers' if severity_val > 0.6 else 'Standard inspection protocols apply'}
â€¢ Document findings in vehicle maintenance log

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**TECHNICAL NOTES**
Analysis Method: Automated anomaly detection using {pipeline_name or 'statistical pattern recognition'}
Detection Confidence: {'High (>85%)' if severity_val > 0.6 else 'Medium (60-85%)' if severity_val > 0.3 else 'Low (<60%)'}

This is a rule-based analysis. For advanced AI-powered natural language insights,
consider installing LLaVA vision-language model components.
"""

    return report


def llava_generate(ref_img, test_img, heatmap, mask_final, pipeline_type="semantic", severity=None, features=None, pipeline_name=None):
    """
    Generate natural language report using LLaVA

    Args:
        ref_img: Reference image (RGB)
        test_img: Test image (RGB)
        heatmap: Difference heatmap
        mask_final: Final segmentation mask
        pipeline_type: "semantic" or "anomaly"
        severity: Anomaly severity score (for anomaly pipelines)
        features: Routing features dict (optional)
        pipeline_name: Name of the pipeline (optional)

    Returns:
        report: Natural language explanation
    """
    model, tokenizer = get_llava_model()

    # Calculate mask area
    mask_area = np.sum(mask_final > 0) if mask_final is not None else 0

    # Fallback to rule-based if LLaVA unavailable
    if model is None:
        return generate_rule_based_report(pipeline_type, severity, features, mask_area, pipeline_name)

    try:
        # Create composite image for LLaVA
        composite = create_composite_image(ref_img, test_img, heatmap, mask_final)
        composite_pil = Image.fromarray(composite)

        # Prepare prompt based on pipeline type
        if pipeline_type == "semantic":
            prompt = (
                "USER: <image>\n"
                "This is a 2x2 comparison grid showing: (top-left) reference F1 car, (top-right) test F1 car, "
                "(bottom-left) difference heatmap, (bottom-right) detected change mask.\n\n"
                "Analyze the semantic visual differences between the two F1 cars. "
                "Focus on livery changes, color scheme modifications, sponsor branding updates, and design element changes. "
                "Provide a concise technical report.\n"
                "ASSISTANT:"
            )
        else:  # anomaly
            prompt = (
                "USER: <image>\n"
                "This is a 2x2 comparison grid showing: (top-left) reference F1 car, (top-right) test F1 car, "
                "(bottom-left) anomaly heatmap, (bottom-right) detected anomaly mask.\n\n"
                f"Analyze potential structural anomalies or damage. Severity: {severity:.2f if severity else 0.0}. "
                "Focus on tire damage, bodywork issues, surface defects, or structural irregularities. "
                "Provide a concise technical assessment.\n"
                "ASSISTANT:"
            )

        # Generate
        import torch
        inputs = tokenizer(prompt, composite_pil, return_tensors="pt").to(model.device)

        with torch.no_grad():
            output = model.generate(**inputs, max_new_tokens=200, do_sample=False)

        report = tokenizer.decode(output[0], skip_special_tokens=True)

        # Extract only the assistant's response
        if "ASSISTANT:" in report:
            report = report.split("ASSISTANT:")[-1].strip()

        return report

    except Exception as e:
        print(f"Warning: LLaVA generation failed: {e}")
        return generate_rule_based_report(pipeline_type, severity, features, mask_area, pipeline_name)
